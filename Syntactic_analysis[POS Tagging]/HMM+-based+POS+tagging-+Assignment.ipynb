{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi\n",
    "\n",
    "In this assignment we try to deal with unknown words which is a problem in the Vanilla Viterbi Algorithm. There are many differnet ways to achieve this. For example we can use only transition probability whenever emission probabilty is zero, use transition probability weighted by tag occurence, rule based tagger etc. In this project we concentrate on the below 2 methods:\n",
    "\n",
    "> **1) In the first method we use transition probabilities weighted by tag occurence probability for unknown words.**\n",
    "\n",
    "> **2) In the second method we define rules and then backoff to the rule based tagger in case of unknown words.**\n",
    "\n",
    "Finally, we test the modified algorithm on the validation set and the entire test set and then finally list the words that have been correctly tagged by the modified Vitterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "#print(nltk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "train_set,test_set = train_test_split(nltk_data,train_size=0.95,test_size=0.05)\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12045\n",
      "12\n",
      "{'ADP', 'PRT', 'CONJ', 'PRON', '.', 'ADJ', 'NOUN', 'DET', 'VERB', 'X', 'NUM', 'ADV'}\n"
     ]
    }
   ],
   "source": [
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "tokens = set([pair[0] for pair in train_tagged_words])\n",
    "tags = set([pair[1] for pair in train_tagged_words])\n",
    "print(len(tokens))\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the HMM algorithm to tag the words. Given a sequence of words to be tagged, to every word w, assign the tag t that maximises the likelihood P(t/w).\n",
    "\n",
    "Since <font color=red>P(t/w) = P(w/t). P(t) / P(w)</font>, after ignoring P(w), we have to compute P(w/t) which is the probability of emission of word given a tag or the emission probability and P(t) which is the transition probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute emission and transition probabilities\n",
    "\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    "        \n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger\n",
    "\n",
    "Now we will implement the vanilla viterbi algorithm which assigns the tag which has the maximum probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            (count_wgt, count_t) = word_given_tag(words[key], tag)\n",
    "            emission_p = count_wgt/count_t\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sentences\n",
    "print(len(test_set))\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sentences\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  13.150871276855469\n",
      "Vanilla Viterbi Algorithm Accuracy:  90.51724137931035\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Vanilla Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Knowing', 'ADP'), ('Knowing', 'VERB')),\n",
       " (('tasty', 'ADP'), ('tasty', 'ADJ')),\n",
       " (('eat', 'ADP'), ('eat', 'VERB')),\n",
       " (('standing', 'NOUN'), ('standing', 'ADJ')),\n",
       " (('ovation', 'ADP'), ('ovation', 'NOUN')),\n",
       " (('Huber', 'ADP'), ('Huber', 'NOUN')),\n",
       " (('introduces', 'ADP'), ('introduces', 'VERB')),\n",
       " (('anti-miscarriage', 'ADP'), ('anti-miscarriage', 'ADJ')),\n",
       " (('that', 'ADP'), ('that', 'DET')),\n",
       " (('short', 'ADJ'), ('short', 'ADV')),\n",
       " (('chase', 'ADP'), ('chase', 'VERB'))]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe above, the **vanilla viterbi algorithm** has tagged many words as unknown. As a result the accuracy of the algorithm is also just **around 92%**. The accuracy changes slightly for every run as we randomly choose only 5 sentences from the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words\n",
    "\n",
    "We can see above that most of the unknown words are incorrectly tagged as X. Lets first try to solve this problem using the concept of assigning weighted probabilities to the tags\n",
    "\n",
    "###### Viterbi Modification 1: Using transition probabilities weighted by tag occurence probability for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ADP', 0.09778932045951974),\n",
       " ('PRT', 0.03202396037322889),\n",
       " ('CONJ', 0.022525683048664272),\n",
       " ('PRON', 0.02722769685101214),\n",
       " ('.', 0.11636698746478726),\n",
       " ('ADJ', 0.06338817270737557),\n",
       " ('NOUN', 0.2871684242494057),\n",
       " ('DET', 0.08659454817731514),\n",
       " ('VERB', 0.1346828496926412),\n",
       " ('X', 0.06578630446848394),\n",
       " ('NUM', 0.03485145196929554),\n",
       " ('ADV', 0.03159460053827062)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_prob = []\n",
    "total_tag = len([tag for word,tag in train_tagged_words])\n",
    "for t in tags:\n",
    "    each_tag = [tag for word,tag in train_tagged_words if tag==t]\n",
    "    tag_prob.append((t,len(each_tag)/total_tag))\n",
    "\n",
    "tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_mod_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "       \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            (count_wgt, count_t) = word_given_tag(words[key], tag)\n",
    "            emission_p = count_wgt/count_t\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p             \n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use weighted transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]                 \n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken(s):  13.774160623550415\n",
      "Modified Viterbi Accuracy:  93.96551724137932\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_mod_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken(s): \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('tasty', 'NOUN'), ('tasty', 'ADJ')),\n",
       " (('standing', 'NOUN'), ('standing', 'ADJ')),\n",
       " (('introduces', 'NOUN'), ('introduces', 'VERB')),\n",
       " (('anti-miscarriage', 'NOUN'), ('anti-miscarriage', 'ADJ')),\n",
       " (('that', 'ADP'), ('that', 'DET')),\n",
       " (('short', 'ADJ'), ('short', 'ADV')),\n",
       " (('chase', 'NOUN'), ('chase', 'VERB'))]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that by **using the weighted modification, the accuracy has increased by more than 4% to around 96%**. We can see that words like **roof, more, inches etc have been correctly taged** compared to the vanilla Viterbi. However there are still many words that are wrongly tagged. Lets use a rule based approach to solve this issue\n",
    "\n",
    "\n",
    "###### Viterbi Modification 2: Rule based tagging\n",
    "\n",
    "Here we define the set of rules to choose from when an unknown word occurs. At the end we have a default tag for Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense   \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'^[A-Z][a-z].*', 'NOUN'),       # NOUN\n",
    "    (r'.*', 'NN')                     # default\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_mod_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            (count_wgt, count_t) = word_given_tag(words[key], tag)\n",
    "            emission_p = count_wgt/count_t\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1] \n",
    "        \n",
    "      \n",
    "        # getting state for which probability is maximum\n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "            \n",
    "            # if unknown word does not satisfy any rule, find the tag with maximum transition probability\n",
    "            if state_max == 'NN':\n",
    "                pmax = max(p_transition)\n",
    "                state_max = T[p_transition.index(pmax)]                 \n",
    "                \n",
    "        else:\n",
    "             if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken(s):  13.609601736068726\n",
      "Modified Viterbi Accuracy:  93.96551724137932\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_mod_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken(s): \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('tasty', 'NOUN'), ('tasty', 'ADJ')),\n",
       " (('standing', 'NOUN'), ('standing', 'ADJ')),\n",
       " (('introduces', 'NOUN'), ('introduces', 'VERB')),\n",
       " (('anti-miscarriage', 'NOUN'), ('anti-miscarriage', 'ADJ')),\n",
       " (('that', 'ADP'), ('that', 'DET')),\n",
       " (('short', 'ADJ'), ('short', 'ADV')),\n",
       " (('chase', 'NOUN'), ('chase', 'VERB'))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the **accuracy has increase further by about 5% to 97%** compared to vanilla Viterbi and most of the words have been correctly tagged. The accuracy can be further increased by defining more rules. Now lets evaluate the algorithms on the test set provided\n",
    "\n",
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android is a mobile operating system developed by Google.',\n",
       " 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.',\n",
       " \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
       " 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.',\n",
       " 'Before entering politics, Donald Trump was a domineering businessman and a television personality.',\n",
       " 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.',\n",
       " 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.',\n",
       " 'Show me the cheapest round trips from Dallas to Atlanta',\n",
       " 'I would like to see flights from Denver to Philadelphia.',\n",
       " 'Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.',\n",
       " 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('Test_sentences.txt')\n",
    "\n",
    "text = f.read()\n",
    "\n",
    "sample = text.splitlines()\n",
    "\n",
    "f.close()\n",
    "\n",
    "sample = sample[:-3]\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_words = [word for sent in sample for word in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  16.96497631072998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Android', 'ADP'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'ADP'),\n",
       " ('Android', 'ADP'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'ADP'),\n",
       " ('worldwide', 'ADP'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'ADP'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'ADP'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'ADP'),\n",
       " ('Google', 'ADP'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'ADP'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'ADP'),\n",
       " ('that', 'DET'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'ADP'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'ADP'),\n",
       " ('firehose.', 'ADP'),\n",
       " ('Twitter', 'ADP'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'ADP'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'ADP'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'ADP'),\n",
       " ('known', 'ADJ'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'ADP'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'ADP'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'ADP'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'ADP'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'ADP'),\n",
       " ('FIFA', 'ADP'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'ADP'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'ADP'),\n",
       " ('FIFA', 'ADP'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'ADP'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'ADP'),\n",
       " ('contested', 'ADP'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'ADP'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'ADP'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'ADP'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'ADP'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'ADP'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'ADP'),\n",
       " ('NASA', 'ADP'),\n",
       " ('invited', 'ADP'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'ADP'),\n",
       " ('Satellite.', 'ADP')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi(sample_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the Vanilla Viterbi algorithm on the test set, we can observe that there are many words that have been incorrectly tagged. Words such as Android, Google, OS, smartphones, worldwide etc are tagged as X. Now lets run the rule based tagger Viterbi modification and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  17.018357515335083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NOUN'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NOUN'),\n",
       " ('firehose.', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'NOUN'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'NOUN'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'NOUN'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'NOUN'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'VERB'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'NOUN'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'NUM'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'VERB'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'NOUN'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'NOUN'),\n",
       " ('NASA', 'NOUN'),\n",
       " ('invited', 'VERB'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'NOUN'),\n",
       " ('Satellite.', 'NOUN')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi_mod_2(sample_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be clearly observed that the modified algorithm is performing pretty well on the test set as well. \n",
    "- **Words such as Android, Google, OS, smartphones, worldwide etc are corretly tagged as NOUN and 2011 as NUM etc**\n",
    "\n",
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The accuracy of Vanilla Viterbi algorithm was found to be around 92%**\n",
    "- **The accuracy of Viterbi modification 1 which is using weighted tags is around 96%** and\n",
    "- **The accuracy of Viterbi modification 2 which is using using rule based tagger is around 97.5%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are some of the words which were incorrectly tagged and was corrected using the modified Viterbi tagger\n",
    "\n",
    "###### - roof: Correctly tagged as NOUN\n",
    "###### - inches: Correctly tagged as NOUN\n",
    "###### - duo: Correctly tagged as NOUN\n",
    "###### - disclosures: Correctly tagged as NOUN\n",
    "###### - *-92: Correctly tagged as X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the test set file:\n",
    "\n",
    "###### - Words such as Android, Google, Twitter, OS, FIFA, smartphones, worldwide etc are corretly tagged as NOUN and \n",
    "###### - 2011, 2013, 2015 correctly tagged as NUM \n",
    "###### - domineering correctly tagged as VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
